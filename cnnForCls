import cv2
from glob import glob
import numpy as np
import tensorflow as tf
import time
import tensorflow as tf
import numpy as np
from sklearn.model_selection import train_test_split

def wight_varible(shape):
    initial = tf.truncated_normal(shape,stddev = 0.1)
    return tf.Variable(initial)
def bias_variable(shape):
    initial = tf.constant(0.1,shape=shape)
    return tf.Variable(initial)
def conv2d(x,W):
    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')
def fc(input, w, b):
    return tf.matmul(input, w) + b
def train(Xtrain, Xtest, Ytrain, Ytest,epochs=1500,batchSize = 100):
    with tf.name_scope('input'):
        x = tf.placeholder(tf.float32, shape=[batchSize, 10],name = 'x_input')
        y = tf.placeholder(tf.float32, shape=[batchSize, 2],name = 'y_input')
        prob = tf.placeholder(tf.float32,name='prob')
    with tf.name_scope('fc1') as scope:
        kernel = wight_varible([10, 4096])
        biases = bias_variable([4096])
        fc0 = tf.nn.relu(fc(x, kernel, biases), name=scope) #(?,4096)
        fc1 = tf.reshape(fc0,(batchSize,64,64,1))
    with tf.name_scope('layers'):
        with tf.name_scope('layer1'):
            with tf.name_scope('W1'):
                W_conv1 = wight_varible([2, 2, 1, 20])
            with tf.name_scope('b1'):
                b_conv1 = bias_variable([20])
            with tf.name_scope('h1'):
                h_conv1 = (conv2d(fc1, W_conv1) + b_conv1)  # (?,123,440,20)
            with tf.name_scope('BN1'):
                h_conv1 = tf.contrib.layers.batch_norm(inputs=h_conv1,decay=0.9,is_training=True,updates_collections=None)
            with tf.name_scope('relu1'):
                h_conv1 = tf.nn.relu(h_conv1)
            with tf.name_scope('drop_out1'):
                h_conv1 = tf.nn.dropout(h_conv1, prob)
        with tf.name_scope('layers2'):
            with tf.name_scope('W2'):
                W_conv2 = wight_varible([3, 3, 20, 30])
            with tf.name_scope('b2'):
                b_conv2 = bias_variable([30])
            with tf.name_scope('h2'):
                h_conv2 = (conv2d(h_conv1, W_conv2) + b_conv2)  # (?,123,440,30)
            with tf.name_scope('BN2'):
                h_conv2 = tf.contrib.layers.batch_norm(inputs=h_conv2, decay=0.9, is_training=True, updates_collections=None)
            with tf.name_scope('relu2'):
                h_conv2 = tf.nn.relu(h_conv2)
            with tf.name_scope('drop_out2'):
                h_conv2 = tf.nn.dropout(h_conv2, prob)
        with tf.name_scope('layers3'):
            with tf.name_scope('W3'):
                W_conv3 = wight_varible([5, 5, 30, 30])
            with tf.name_scope('b3'):
                b_conv3 = bias_variable([30])
            with tf.name_scope('h3'):
                h_conv3 = (conv2d(h_conv2, W_conv3) + b_conv3)  # (?,123,440,30)
            with tf.name_scope('BN3'):
                h_conv3 = tf.contrib.layers.batch_norm(inputs=h_conv3, decay=0.9, is_training=True, updates_collections=None)
            with tf.name_scope('relu3'):
                h_conv3 = tf.nn.relu(h_conv3)
            with tf.name_scope('drop_out3'):
                h_conv3 = tf.nn.dropout(h_conv3, prob)
        with tf.name_scope('layers4'):
            with tf.name_scope('W4'):
                W_conv4 = wight_varible([3, 3, 30, 30])
            with tf.name_scope('b4'):
                b_conv4 = bias_variable([30])
            with tf.name_scope('h4'):
                h_conv4 = (conv2d(h_conv3, W_conv4) + b_conv4)  # (?,123,440,30)
            with tf.name_scope('BN4'):
                h_conv4 = tf.contrib.layers.batch_norm(inputs=h_conv4, decay=0.9, is_training=True, updates_collections=None)
            with tf.name_scope('relu4'):
                h_conv4 = tf.nn.relu(h_conv4)
            with tf.name_scope('drop_out4'):
                h_conv4 = tf.nn.dropout(h_conv4, prob)
        with tf.name_scope('layer5'):
            with tf.name_scope('W5'):
                W_conv5 = wight_varible([5, 5, 30, 20])
            with tf.name_scope('b5'):
                b_conv5 = bias_variable([20])
            with tf.name_scope('h5'):
                h_conv5 = (conv2d(h_conv4, W_conv5) + b_conv5)  # (?,123,440,20)
            with tf.name_scope('bn'):
                h_conv5 = tf.contrib.layers.batch_norm(inputs=h_conv5, decay=0.9, is_training=True, updates_collections=None)
            with tf.name_scope('relu5'):
                h_conv5 = tf.nn.relu(h_conv5)
            with tf.name_scope('drop_out5'):
                h_conv5 = tf.nn.dropout(h_conv5, prob)
        with tf.name_scope('layer6'):
            with tf.name_scope('W6'):
                W_conv6 = wight_varible([3, 3, 20, 10])
            with tf.name_scope('b4'):
                b_conv6 = bias_variable([10])
            with tf.name_scope('h6'):
                h_conv6 = (conv2d(h_conv5, W_conv6) + b_conv6)  # (?,123,440,10)
            with tf.name_scope('bn6'):
                h_conv6 = tf.contrib.layers.batch_norm(inputs=h_conv6, decay=0.9, is_training=True, updates_collections=None)
            with tf.name_scope('relu6'):
                h_conv6 = tf.nn.relu(h_conv6)
            with tf.name_scope('drop_out6'):
                h_conv6 = tf.nn.dropout(h_conv6, prob)
        with tf.name_scope('layer7'):
            with tf.name_scope('W7'):
                W_conv7 = wight_varible([5, 5, 10, 1])
            with tf.name_scope('b7'):
                b_conv7 = bias_variable([1])
            with tf.name_scope('relu7'):
                h_conv7 = tf.nn.relu(conv2d(h_conv6, W_conv7) + b_conv7)  # (?,123,440,1)
        # fc2
        with tf.name_scope('fc2') as scope:
            shape = int(np.prod(h_conv7.get_shape()[1:]))
            kernel = wight_varible([shape, 4096])
            biases = bias_variable([4096])
            flat = tf.reshape(h_conv7, [-1, shape])
            fc2 = tf.nn.relu(fc(flat, kernel, biases), name=scope)
        # fc3
        with tf.name_scope('fc7') as scope:
            kernel = wight_varible([4096, 2])
            biases = bias_variable([2])
            fc3 = tf.nn.relu(fc(fc2, kernel, biases), name=scope)
        finaloutput = tf.nn.softmax(fc3, name="softmax")
    with tf.name_scope('loss'):
        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=finaloutput, labels=y))
        tf.summary.scalar('loss',loss)
    with tf.name_scope('optimister'):
        optimize = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)
    print("Training ...")
    saver = tf.train.Saver()
    tf.add_to_collection('finaloutput', finaloutput)
    loss_courve = tf.summary.merge_all()
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        writer = tf.summary.FileWriter('./logs/',sess.graph)
        for epoch in range(epochs):
            sess.run(optimize, feed_dict={x: Xtrain, y: Ytrain,prob:0.7})
            summary,_ = sess.run([loss_courve,optimize],feed_dict={x:Xtrain, y: Ytrain, prob: 1})
            writer.add_summary(summary,epoch)
            loss_val = sess.run(loss, feed_dict={x: Xtrain, y: Ytrain,prob:1})
            print('Epoch', epoch, ' Loss:',loss_val )
            #test accuc
            # prid = sess.run(optimize, feed_dict={x: Xtrain, y: Ytrain, prob: 1})
            if (epoch+1) % 250 == 0:
                saver.save(sess, "./model_test/lane-conv1", global_step=epoch)
def readData():
    dataPath = r"./建模相关数据.csv"
    X = []
    Y = []
    buffer = open(dataPath,"r").readlines()
    for lineIndex in range(1,len(buffer)):
        line = buffer[lineIndex].split(",")
        tmp = line[31:41]
        tmp = [float(x) for x in tmp]
        X.append(tmp)
        tmp = int(line[42])
        tmp = [1,0] if tmp == 1 else [0,1]
        Y.append(tmp)
    X = np.array(X)
    Y = np.array(Y)
    print("X.shape = {},Y.shape = {}".format(X.shape,Y.shape))
    return X,Y
if __name__ == "__main__" :
    X,Y = readData()
    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X,Y,test_size=0.3,random_state=420)
    print("Xtrain.shape,Xtest.shape :",Xtrain.shape,Xtest.shape)
    print("Ytrain.shape,Ytest.shape :",Ytrain.shape,Ytest.shape)
    train(Xtrain = Xtrain ,Ytrain = Ytrain, Xtest = Xtest, Ytest = Ytest,epochs=4000,batchSize = Xtrain.shape[0])

